---
title: Beyond the Pilot: Enterprise AI Implementation - VentureBeat Podcast with Ryan Nestrom (Notion)
source: 2025-11-19_ai_venturebeat-launches-beyond-the-pilot--a-new-po.md
date_added: 2025-11-19
last_updated: 2025-11-19
tags: [enterprise-ai, ai-agents, notion, product-development, ai-implementation]
source_type: video
---

## Summary

- VentureBeat launches 'Beyond the Pilot' podcast focusing on real-world enterprise AI implementation beyond experimental phases
- Ryan Nestrom from Notion discusses building AI agents into Notion 3.0, drawing parallels between the mobile revolution (iPhone era) and current AI transformation
- Key theme: Enterprise AI conversation shifting from 'dreaming big' to 'building sustainable solutions' with real ROI considerations
- Notion's approach: Injecting AI intelligence into existing non-AI-native products used by millions, focusing on making AI work within established systems
- Emphasis on learning from trade-offs and real experiences - no single answer for AI implementation

## Key Insights

- The AI conversation is maturing from experimentation to sustainable implementation - companies are now asking 'what actually works?' rather than 'what's possible?'
- Ryan Nestrom compares current AI evolution to iPhone 4 era (not iPhone 1) - past the initial novelty, entering the phase of real capability and ecosystem development
- Non-AI-native companies face unique challenge: teaching AI complex existing systems vs. making systems speak AI's language - integration over disruption
- AI implementation playbooks are becoming outdated within 6 months, requiring continuous intelligence gathering and adaptation
- Success in AI requires focusing on bringing developer-level productivity gains to everyday users and workflows

## Full Content



## Video: https://youtube.com/watch?v=w5xtbdoPfTg

**Video ID**: w5xtbdoPfTg

### Transcript

Hello, I'm Matt Marshall, founder and editor-inchief of VentureBeat, and I'm excited to share a new podcast project we've been working on. We're calling it Beyond the Pilot: Enterprise AI in action. At Venturebe, we have conversations every day with leaders and teams across various industries to bring you coverage about the latest in enterprise AI. And from my vantage point, the conversation has really started to change from, can I dream as big as I can to a question of, hey, can I actually just build something that's sustainable and really works for me? That race to scale fueled by supposedly neverending cloud resources is colliding with brutal realities of physics and finance and ROI. Let's be honest, over the last 6 months, I bet your AI playbook has become outdated. I've teamed up with my friend Sam Whitphine, who's a developer and a leader in AI coverage to dive into what real companies, industry leaders, and decision makers are actually doing and to learn about their experiences putting AI into action. We're hoping to uncover what they've done wrong, what they've done right, and how they've overcome real problems as they've moved beyond the pilot. So, I think your task is really to listen for those trade-offs. There's not one single answer. You're going to have to gather intelligence for your playbook, and the space is moving really quickly. We're going to keep up with that conversation. So, thank you for listening. Here's the first episode. This is Venture Beats Beyond the Pilot, Enterprise AI in action. I'm Samine. >> I'm Matt Marshall. Today's episode is presented by Outshift by Cisco, Cisco's emerging tech incubation engine and driver of Aentic AI, Quantum, NextG, Infra, and beyond. Today we're talking with Ryan Nestrom, who's helped build some of the products that have defined the mobile era at places like Instagram. He's also created a bunch of popular iOS libraries. And Brian currently leads the AI team at Notion that has recently built Notion 3.0 for agents. So, this is creating agents right inside the second brain that's used by millions of users. For us, what makes Notion story so compelling is that they weren't an AI native company. They're injecting this new intelligence into a product that people have been relying on for a number of years already. Ryan's been on the front lines discovering the differences between trying to teach your AI a complex system versus getting your system to speak the AI's language. Welcome to the pod, Ryan. It's great to have you. >> Thank you so much. I'm excited to jump into some of the things we did uh on notion's AI and agent systems. >> So I I kind of think that you've got a really interesting sort of perspective in like I mentioned in the intro, you've got this history in the mobile era and you know you you worked at sort of one of the premier sort of uh companies that took mobile to to the next level kind of thing being Instagram. Um, not only that, along the way you you built a bunch of sort of, you know, uh, well-known iOS libraries, uh, wi with that you were very involved in that community. I'm kind of interested to sort of get your a little bit of your history of how you thought about that back then. Uh, and then how did that transition into where you are now at notion? Yeah, I I got my start basically in engineering and coding um because of of mobile because of the iPad and the iPhone. Um I was just kind of wowed by this technology that I could not only take with me but also like touch and interact with. And that's what really got me excited. Um, I also really felt like back when I when I was getting started in like 2010, 2011, um, we were in the middle of this like revolution where everything was switching to mobile and one of my one of my my first really big tech job was was working at Instagram and kind of riding that wave of everyone I mean, you know, Instagram being owned by Facebook where people were migrating from doing things on their computer on Facebook to sharing and socializing on their phone. Um, and I found that really exciting. Um, I wanted to build product. I wanted to build tools. I wanted to build things that people could touch and use. And what really gets me excited about this time in AI is I'm feeling the same sort of like wow and like magic with these tools. um you know comparing like LMS today which are already extremely advanced um with things like GPD5 and Sonnet 45 which are kind of the latest latest and greatest frontier models. It's almost like you compare these to when I got started with iPhone. It was like the iPhone 4, you know, it wasn't the first gen. It wasn't the iPhone 1 which like was kind of magic but like was super limited. Didn't have an app store or anything. Um, and we went through these different phases of the iPhone where they got faster, sleeker, more powerful. Um, got the app store, you had more SDKs, more APIs, and more things that you could do. Then we had more hardware like the iPad, um, the watch. And I feel like this is kind of happening again um, in the industry with LMS and with AI. Um, we're getting tool calling. uh we're getting more and more features like the companies are building you their own versions of like app stores and computer use and browsers and all these things. Um and we don't know exactly like where this is going to go but we see the value in the technology and so we're all just trying to like build things and figure out how to like make this work for us. um you know a as somebody who writes code like it's become like immensely valuable to my workflow and now we're trying to like expand that value to like everyday tasks. Um and that's what I'm trying to do here at at notion as well like we have this platform we have this product how can we bring that sort of joy and magic that we're experiencing on the engineering side to uh this productivity software. So that's super interesting that you're starting to see this explosion like you mentioned, you know, originally from the mobile era, now this AI era. Um, can you tell us a little bit about how you got involved in notion, where, you know, sort of notion was perhaps with their AI journey when you first uh arrived? >> Yeah, it's it's a little funny. I was doing a startup um with one of my uh great friends and founder co-founder um and we were trying to build uh we have this sort of like vendetta against Slack. I I think that Slack can be like >> Yeah. This is a kind of a fault of my own. Like I the pings and the badges and the alerts happen and I'm like eager to go help people and unblock, but I'll like then I'll end my day having been like, "Oh my god, I've just been in Slack all day." Like I didn't write any code. Uh so we were building this startup to to try and solve some of that problem. Um it was more of like a writing focused uh product, but still was for like async remote work. Um and we did our startup for a few years. it never got like the traction that we wanted and um you know at the time the the the sort of irony is that like on our website at one time we had like you should not use notion you should use our software instead and that like I think put each other on each or put us on each other's radars and um when our startup wasn't working we uh we reached out to some folks at notion and found out that like us actually would be kind of share the same like design language and product philosophy fee um and found a found a great home and opportunity over here. And originally we were not even going to come to work on AI um because we had been working on like workplace comms and communication and stuff. But as soon as we joined um there was this sort of resurgence into notion's AI tools and systems and we were uh there was a lot of experimental stuff going on at the time. Um, and it was very uh experimental and innovative in terms of like the way we were using uh LMS and AI, but we needed to put some like product finesse on it. Um, and my co-founder uh Brian Leven uh is a designer. I'm an engineer. Both of us are like product people as well. And so we were able to join this like extremely technical project and put like a product lens on it. Um, and we went through a bunch of different iterations of what it should have been. Um, we were exploring crazy stuff like codegen within notion and all these really wild automations. Um, they were incredibly impressive. Uh, and from that we discovered um this sort of like agentic loop and tool calling loop um that worked really really well and we leaned really hard into that and that is eventually what became our notion 3.0 moment um that we announced at make with notion this year. >> Ryan and very interesting we want to get further into that product obviously. Um going back to briefly to um the experience you had during the mobile era, right? You mentioned that feeling of being on the bleeding edge again of you know chasing new APIs. >> Um one of the things about mobile though is you built software and you had the iOS system and platform. It worked right that was the beauty of iOS. You know obviously Android was a competitor. How is building that stochastic you know non-deterministic AI product different when you when you go back to that era of excitement um you know you know how is it different now from that deterministic world where things worked right the traditional software mobile engineering background that you have I yeah I still really struggle with this um because I I've got you know over a decade of like trai almost want to like traditional software engineering ing experience where I'm like it's extremely deterministic. Um when I write code that expects this output like it is so simple to understand debug. Um there were when I started working with AI at at our former startup, we were doing a little bit of a AI stuff and then coming here um I really had to like rewire myself to like understand how to work with these things. And one of my like key moments was when I was working with um one of our our co-founders at Notion, Simon, um said something about uh was giving me feedback on like a code change that I was making, a prompt change, and he was like, "Describe this as you would describe to an intern." And I was like, "Well, like I'm trying to like codify the rules of how this like LM should behave in this condition." And he's like, "Yeah, yeah, but like these are trained on like content generated by people and so they they are going to like understand or reason better like people will." And that was just like a light bulb moment to me that I was like, "Oh man, I'm really like it's almost like an organic thing like I'm like talking to it and explaining to it." And really now whenever I'm like working with AI, I'm starting to I will like reread the prompts and and tool descriptions and all these things and be like, is this something that I could give to a person with like no context and they could somewhat understand what's going on. If not, then it's going to do a bad job. Um, and that's like fun because there's like so much logic that can be baked into just like English instructions. It's also like as a traditional software person like kind of horrifying because sometimes things work in ways that are incredibly unpredictable. Um, they can go sideways. They can interpret things differently. And then you add into the mix um like different models uh that like have their own preferences and behaviors and like training data built in. So it's I find it like very like weird but in a fun way. Like it's really it's really fun weird um because you can end up doing a lot of like really interesting quirky things um with LMS. This series is presented by Outshift, Cisco's emerging tech incubation engine and driver of the internet of agents, an open interoperable internet for agent-to-agent collaboration. Learn more about the internet of agents and explore how Agentic systems are the future at outshift.isco.com. And Ryan, where do you feel like we are on that journey? Right. I think there's a there's a sense that we we were obviously scaling the models. Um there's improvement through reinforcement learning, right? There's the reasoning. There's there is this trajectory, but there there there's also kind of this brewing discontent with hallucinations and and the limits of of that reasoning, right? There was talk of AGI, right? AGI was around the corner. um that's all disappeared as you joined the company and and where and where you are where you feel things are now. Can you give us a sense of where we are on that that journey? >> I I really feel, you know, using uh this like mobile comparison. It's almost like we're in the like Palm OS era. We're like pre BlackBerry pre pre iPhone, you know? It's like it's so I think it is so early. Um, I I think that there's a lot of valid criticism of what LLMs and especially like agentic systems are capable of. And that's that's one thing that I think we've learned the hard way building um not even just the current version of Notion AI, but like the previous iterations of it. And the thing that gets me excited though is like the pace of change is like so fast that you know it'd be almost like if we there were plenty of people who like poo pooed the palm pilot and we're like ah this is like going nowhere. Like it can barely like detect my like handwriting when I'm like doing um the like notation on it. But like look where we are now. I mean look how much it's changed in what 30 years like less. Um, I I think that like there's a lot of of comparisons and I think that things are moving like even faster because like GPT 3 was like a couple years ago and that was like okay. I mean GPD4 I think a lot of us was like the breakthrough moment and and that even compared to what things can do now which is like a year and a half later or something. I mean it's crazy this stuff is changing so fast. Do you do you find it's different this time though in that like before you kind of had to pick your camp, right? You were either iOS or you were Android, right? And and and you would never go from one to the other kind of thing, right? We But now people, you know, it it's it's almost like people are, you know, happily changing models every, you know, every week kind of thing or if not even sooner. So do you I'm curious to sort of get your take on how do you see the differences between say an open AI with the GPT models the clawed models from anthropic perhaps Google or the the other Chinese companies etc. I I I love that. Um I I remember when I got like very into mobile I was just like diehard Apple like Android sucks. It's never going to be that good. it and you know working on Instagram we had like a handful of iOS engineers and we had a handful of like Android engineers and like we very like the cultures were so different the people were so different. Um though the fun fact is that like probably nine out of 10 Android engineers used an iPhone. So like I think that iPhone was clear was clearly the choice. Anyways, uh but I what I love about the the current state of things is that um these like frontier models are competing with each other or not not the models but like these frontier research labs are competing with each other and they are learning from each other. Uh they are innovating they're they are sharing information. they're also like keeping um some of their their biggest innovations, you know, uh secret and stuff. And I I just think that this competition is really good um for the industry. Um for us at Notion, we benefit because these frontier labs are trying to like build the best model and they're trying to out compete each other and then we are just going to use the one that fits our needs the best. Um, and so we are constantly evaluating uh the new models. We pretty much are are staying in the like anthropic and open AI camps. Um, it that's that's what's just worked out best for us. We'll always play with new models as they come out. Um, but it is it is quite different. You you will get some people that are like, "Oh, GBD5 like picks up on my writing style or it's got a um a way of doing tool calling that's preferable to me." And um I think that that's I think that that's great, but I also notice the way that these are changing so quickly. Um you know, Sonnet 45 came out like a a month month and a half ago or something. And it like one of our biggest issues with Sonnet 4 is it would only do tool calls kind of like one at a time and wouldn't do them in parallel very often. And four five is all of a sudden just like I'll do as many tools at once as I think is is um necessary. And that was like a huge leap forward. And now I'm like, "Oh, Sonic 45 is like pretty great now." Um, and so, and I even I even see that on like the tools that I use, like I will flip-flop between Cloud Code and Codeex pretty regularly based on uh either model innovations or even just like product innovations. Um, and so it it is cool that I don't think people are stuck in one camp um very much. You know, there was such a clear difference between like Apple um or like iOS and Android. Like there were just things that one prioritized over the other. Android being like very open, iOS being like closed but also like super polished, super performant. Um that's changed nowadays. Uh I think they're both pretty comparable or even, you know, inverted a little bit. Um but yeah, on the model side, um yeah, I I see less like the FFTs. It's not like here at Notion we have a a camp of anthropic engineers and open AAI engineers. We all we all just use LLMs. >> Ryan, you describe Notion's journey into Gen AI is almost an accident built on years of prior work. Can can you unpack the pre-existing ingredients like search connected apps and and the collaborative editor that Notion had that became the foundation for your agent? >> Yeah. Yeah. I I I know it wasn't like uh an accident that we created this agentic notion AI, but like when I kind of replay how we got here, it it it almost feels like the stars aligned. So like notion's history um briefly because I've only been here, you know, one year out of I think Notion's been around. I mean Notion as like a company uh with the co-founders has been around for like 13 years. um in its current form I think since 2016 2017 um but essentially notion started as like wikis and pages you know like sort of like collaborative docs they added databases so you could do more project management um and then added things like connected apps where I could connect say GitHub Slack u there's a whole bunch of different connections but those are the two that that I I use a ton um And then I can both like embed content within notion from those apps. And then we started like indexing and um ranking content from those apps so that I could be within notion search for what's one that I love doing. Oh, like what's the Wi-Fi in the New York office? Um and I can like search within content that's already in Notion. But like if that conversation about the Wi-Fi password was also on Slack, our search tools could go out into like the Slack content and find it and then present it to you. And now we can actually use AI to do this like retrieval um augmented generation. You can ask the AI a question and then we could generate say like five different queries or questions for like what you asked and then go out into our um indexes, our vector stores and like go find the content that like closely matches that base and that content could come from GitHub, it could come from Slack and of course it can be within notion itself and then we can take all that information give it back to an LLM and then like ingest and find the answer that you're looking for. Um, and so we ended up building this system which is what we call we'll call it deep find or enterprise search. And so that shipped I think that shipped like two years ago. Um, and then we built this uh with GPT4. We built writer uh we built an assistant within notion. And so we start building these like foundational pieces of using AI within notion. And then fast forward to like this year, we essentially have all of these parts built. We have the core primitives of notion. We have a rich collaborative workspace also rich with like permission checking um uh and those sort of things. We have this block structure in notion that's like highly composable. Um and then we have this advanced search functionality and we have the ability to write with AI. we have like all of this stuff. And so it was like a matter of seeing that all of these pieces already existed in some form and then building a system that can bring them all together. Uh which is what we essentially call our notion agent. Um and so we would build tools that connect to all of these different parts. Tools like search, tools like uh writing to a page, querying a database, um all these sort of things. So yeah, it was it was really like we were we were able to pull together years of work, research, learnings, technology, um, and then assemble it into our current agent. >> Ryan, walk us through maybe if you if you can remember what it what it felt like. So So you joined about a year ago. It's some change plus or minus. Um, so Notion has all these connectors, right? They've been clearly working on Gen AI uh tracking the Gen AI revolution. You're coming in as as you said from the startup, right? With actually not necessarily being on the bleeding edge of Gen AI, right? You're you're trying to kill Slack or something. So, can you can you walk us through >> that founder conversation and what it felt like because essentially it sounds like you came on to actually build the agent. You you said something about how there were maybe two people there working on the project. Can you walk us through what that felt like? >> It really felt like being tossed into the deep end. Um because my my co-founder and I had to learn uh not only AI uh we had to learn aic systems um and we had to learn like notion uh at the same time. Like notion is a a huge codebase. It's a huge codebase. It is um it's pretty complex. Um I I think that like the block system, the permission system, the real time system, not to mention we la we launched offline this year which has its own like uh CRDT or conflict conflict resolution data type system. Um we had to like we had to contend with like all of this stuff. We had to learn all of this stuff and learn how to like most effectively use AI um and be like what is a good product here? Uh, so it was really like having to figure out a bunch of very complicated pieces um at once. But what I've loved is that Notion's like a very prototype forward uh company and the stage that things were at was like really innovative and exciting but also like very cobbled together. Um, and I felt really free to just like go in and play and like break things, change things. Um, and more or less like that culture is still like in the AI team. I mean, we don't we don't kind of like break and hack at the core agent that now that we've like fully launched it, but all the things that we're trying to build on to it or uh extend with it or like that that's very much like the culture still. Um, but it was I it was honestly like crazy. I had no idea what I was doing. It was super complicated. It took me it took me a while to like ramp up and feel um comfortable, but it was a matter of just kind of like powering through it and like trying things. I I also think that like AI is still like in its infancy and so even though I felt like tons of imposttor syndrome, nobody else really knew what they were doing. I mean, we were all just trying to figure this out and like push it to its limits. Um, and so I I was able to play into my strengths, which is like product engineering. Um, and so even though I'm not an AI expert, I can use an AI feature and pretty intuitively figure out like, is this good? Like, is this solving a problem for me? Um, and so I leaned into that really hard. It >> it definitely sounds uh Ryan that that like this was a real sort of aha moment of where you kind of realized that, you know, LLMs are all about context, right? What you put into them. Uh, agents, the same sort of thing. and and notion sitting on this gold mine of context right that whether that's your personal notes in there whether like you you mentioned that you know the connectors to GitHub connectors to other things I how do you sort of like can you tell us a little bit about like was that you know a moment that you sort of realized that what were sort of the experiments that sort of showed oh we've got all this really good structured data in the blocks and stuff like that and perhaps unstructured data from other sources This this was a huge moment for us, you know, like like I mentioned, we were experimenting with like uh really advanced stuff like doing code generation and and all sorts of kind of wild things to help like automate workflows and whatever. And and that has essentially morphed into this like custom agent uh product that we previewed uh like a month ago. But what what was really really exciting for us is we realized that we could just like search and stuff all of this context into the prompt or like the the transcript that we're giving the model. And it was just really good at tool calling like based on that context. Um, and I think one of the like aha moments for us was when we realized we could get rid of a lot of like complicated modeling of our data. Um, and just like break things down into really simple terms for the model. And I I I'll give you a good example. um our prior version of notion AI that we called like the assistant um that lived in the bottom right corner. We'd experimented with uh fine-tuning model on top of frontier models. Uh we'd experimented with pretty complicated rendering of like data within notion like we would use JSON in some places and XML in some places and the models would like do fine. But anytime you're doing this like bespoke um structuring of data, you like have to include instructions about like what this is and you have to like explain it. And a key moment for us was we were trying to figure out how to represent like a page and page content which is this uh very complex tree of blocks. Um and like we had this moment we were like what if we just try to figure out how to present this as markdown like models are trained on lots and lots of markdown. We see all these uh tools and startups that can represent web pages as markdown. We're like, "What if we just represent a notion page as markdown?" And we played with it and the models were like so good and we had like no instructions because all of that context and reasoning about what Markdown is and how to read it, how to understand it, and then most importantly like how to edit it is like all baked in. And we had this moment where we're like, "Oh, we should just use the models how they were like meant to be used." Like it's almost like these native capabilities are built into them. And so then we ended up like rewriting a lot of our systems to be like to the model incredibly stupid like markdown JSON and that's like about it. Like let's not over complicate this. The hard part then came to that like middleware layer where like how do you actually represent a very complex um page block tree as markdown and then on like the flip side of that, how do you let the agent write changes to a like markdown file and then translate that to the very complicated like block structure um within notion. And that's like honestly where a majority of our work went is like that sort of translation layer. Um moving in in and out. >> Do you look at that as the secret source? Like it sounds really interesting that once you kind of realize that oh we've been trying to force the model to do something it didn't want to do but once we realized we got markdown it's just happy to go along with it. is then the secret source actually you sort of writing those passes those sort of systems to be able to go from markdown back to the blocks and I will sort of say I I've actually written some code of writing blocks and it was a real pain a couple years ago when I did it so I can sort of relate to that you know quite a lot but is that something that you sort of see as the secret source of this sort of intermediate middleware kind of thing? >> I I think so. I I think that, you know, a another a really important learning from all of this is that we as human beings like I look I look at notion and I don't see blocks and tree structures and all of this stuff. I just see words on a page. And so for me to effectively communicate with an LM about that content, the the model needs to like I'm air quoting see it needs to see that content almost the same way that I can see it. So that when I say rewrite this paragraph or like change these uh bulleted lists to like numbered lists, it's incredibly obvious to the model like what I'm talking about and like what my intent is. Um, and so I I do think that this sort of representing Notion in a like LLM native way like is kind of the secret sauce to what makes notion AI really good. I also think it's why like uh coding agents are so good is because they're just working with like the file system. Like here is a text file essentially and like the model has tools to interact like read the text file, search for text files and make changes to text files. You don't you don't want to over instruct a model about like here's what to do when the file is Python, here's what to do when the file is TypeScript because the more detail and the more instruction, the more uh chance for confusion and error. Um, so yeah, we spend we spend an enormous amount of time just trying to keep our instructions and our representation of notion data as simple as possible. >> So, so Brian, it makes a lot of sense this this aha moment where okay, so everything's in in markdown. So you have these trees of markdown. where I'd go next and maybe for our listeners is they're probably thinking, okay, well, you just have a a giant rag against that or, you know, maybe the models have have a certain amount of context window to allow that. But what happens when you do have extremely large amounts of of data, you have access to all these files. I mean, this is obviously notion strength. You have connectors everywhere. Maybe this takes us to the tools uh question in terms of how how you do that. Can can you walk us through a little bit more of that secret sauce? >> Yeah, it it is hard. Um and I will admit we've not like perfected it. Um there there are cases where you can load tons and tons of content into your context window and the model will struggle. Um, you know, the more context that you put into the context window, we we do see a degradation in like performance, both like raw like latency, but also like accuracy. Um, it's sort of like you end up with like a needle in a haststack problem and we observe that. So, a couple things that we do, uh, we keep the context like the basic thing is just keep the context as minimal as possible. like don't put stuff in the context window unless essentially the users explicitly ask for it to be there. Um and then we do things like on the search side uh you know within like the internal notion workspace there's just like an enormous amount of data and so if I were to ask what's the New York Wi-Fi password I could get like megabytes of content like if I were to do just like really really basic search. So our search infrastructure is very smart. Um we do that vector search, we rerank things and then we have like a cut off point and then we'll only return that content and then we can summarize that content with another LLM so that only the necessary information that was asked for is presented as context. Um and then another thing that we do is regularly like compact or compress your transcript. So if you're ever conversing with your your agent and we start busting the context window, we can start kind of chunking and compressing um older parts of your transcript which which is itself is sometimes errorprone like that's like a lossy thing. We're essentially like doing a a lossy compression of your past convers conversation and so sometimes that doesn't work as well and and that's something we're trying to improve now. what what what's the sweet spot on like so you know just to get into some specifics I what's sort of a what do you see we know that context when you know can go out to hundreds of thousands if not millions of tokens now what do you guys see as like this is the sweet spot where we're putting enough context in there versus we're not over stuffing it and also costing you a lot of money right we see probably probably in the 100 to 150,000 token limit is like kind of the sweet spot, right? I I I mean I would say less context is better. Um like we don't want to just fill it up with fluff. Um and we we do actively try to avoid that, but we we've borrowed this concept that we see in other like especially like coding tools where you can like add add context like manually. Um, and so using this in notion feels pretty natural. You can just like appment mention a page, a database, a person, um, or whatever. Or you could even just like drop in links, um, to things that are on the web. And then the agent will then pull in whatever that content is as context. Um, but for example, with things like databases, you could have a database with like 100,000 pages in it, and we would not want to put that into the context window because it's going to be giant. um it's going to nerf the models like next respon next response. So we'll do things like present the like highle view of the database and some metadata about it like here's the the columns that they have and then here's maybe like the first three pages that we see and then we have um probably one of our most important tools is our like view tool where you can view the database, you can view pages within the database and so we'll present like the database to the agent and be like here's just some snippets about like what's in it and there's maybe 10,000 pages in it and here's the tools that you can use to like query it or view more things into it. And so we give the agent essentially these tools that if it wants to dig deeper and deeper it can um but we don't like present too much information up front where it like gets confused. Ryan, you you started talking about tools and wondering how much how much of that is a key part of this when Sam and I have been talking with with a number of other companies um you know big you know large enterprise companies pretty sophisticated um domain areas whether it's in banking or or health or legal right Lexus Nexus but we we there's a lot of domain expertise and so they tend to get into training models, fine-tuning models, having, you know, uh, teacher student uh, relationships, a lot of pretty sophisticated stuff. Sounds like you you've kind of >> decided not to go down that path, >> but really have the models reasoning over as much data as possible and then working with things like tools. Is it is is that right? Would you would you would you agree with that? Maybe can you can you provide some context around how important the tool side is? That's exactly right. Um the tools are essentially what makes the notion agent what it is. Um the entire the entire loop of our agent is we give it some basic um documentation essentially about what notion is um and what the user is currently doing. So, we include like what page you're on so that if somebody was like, um, fix my typos in this page, the agent will know what like this page is. Um, and then we just give it a list of tools uh with instructions and documentation and we let it rip. We just let it pick the tools that it thinks is most appropriate. And our engineering team um spends a lot of time trying to keep these tools as simple as possible. Um cuz again if we were to you know in the the MCP world you might have like thousands of tools and modules and things and the agent has to like search through all of that stuff and pick the most effective one. Um, and so we're trying to be really careful about every new tool or even new like tool input or parameter that like it's as minimal and as clear as possible. Like for example, we never want to have like overlapping purpose that I could create a database say um with three different tools because then the agent has to like reason about like okay well I'm on a page should I create a database over here and then move it? should I create a database in line and then like set it up like those can just really confuse it. Um and in the cases that we do have sort of like overlapping um functionality we then like provide instructions about uh in this scenario you would prefer this one. These are kind of like fshot examples. In this example you would use this tool. In this example you would use that tool. Um just to give it a couple hints about how to use these things. So, so I'm really curious on that, right? That we're coming up on the sort of one year first birthday of MCP, right? As we're recording this now, it's just around the corner. I you Notion was one of the companies that jumped into MCP very early. I you know, and and made not only were people sort of making third-party uh you know, MCPs, but Notion themselves decided to make the MCP. Um and I use it with the Claude app. I I love that. I I'm really curious. Did that give you a lot of lessons that you then sort of took into uh you know building out these agents internally and then also how how much do your internal tools match what is sort of you know you're exposing as an external MCP? Yeah, we the the fun fact is that like every tool almost every tool in our MCP uh uses the same tool like almost literally the same tools that our notion AI uses. Um I I think our MCP also has it does more basically than our like internal notion AI does. Can do more things with like uh comments and stuff. Um but all like the core tools the things that you can do with databases and pages it's all it's all shared. Um and there was a lot of did you learn from like watching what everyone was use like what were the was the most popular MCP uh you know sort of tool or function in there and did did that sort of dictate or at least help in designing the actual notion 3.0 agents? >> Um it it did and it didn't. uh we the audience for like our notion AI and then our notion MCP uh isn't like perfectly overlapped like MCP is is a more technical tool like it is you really I mean one you need to know what MCP is uh I could not describe to my mom what MCP is so you like >> you've already kind of like split your your audience um on MCP so like that was one thing uh we were deliberating with like notion AI is like maybe this should just be MCP um but I think that the barrier to entry there is a little steeper um and there's a lot of people there's students you know there's my mom there's like there's people that use notion that don't want to have to think about like the setup and the configuration um and then there's power users uh you know I I use it with cloud code and and codecs myself like the notion MCP and it's like phenomenal Um, but we need to build like a product that can work for like the everyday Notion user as well. And so we did keep that in mind. And I think what was great is we saw what worked really well on the Notion MCP and we adopted some of those best practices. And then like um I was talking about the page and markdown stuff with our Notion AI. We we were able to innovate on that front and then share that back to the Notion MCP. um and then make the Notion MCP better. And so our our teams uh that work on Notion AI and the Notion MCP, we collaborate pretty tightly um and are constantly sharing things that we're learning back and forth um about like what people want from these different products uh and how they're using them, what works well, what doesn't work well. This series is presented by Outshift, Cisco's emerging tech incubation engine and driver of the internet of agents, an open interoperable internet for agent-to-agent collaboration. Learn more about the internet of agents and explore how Agentic systems are the future at outshift.isco.com. Ryan. So, so again, so you joined in January and led what you called this scrappy tiger team to build this agent. Um, you know, and maybe we could come back to MCP here, but um, you know, going back, >> how did you iterate and go from exploration to finding that internal product market fit >> where where people couldn't stop using the tool? >> Um, even you know, even when it was buggy. uh you know and it sounded like it was internal first and I want to get to then maybe some data points about how it was used externally and maybe you know h how people are using the MCP but can you talk a little bit about that product market fit? We almost have this like unspoken rule about product development here that um you know we're we're big users of like internal features, you know, like dog fooding. Um and anytime we have an idea or a feature that is exciting, we have to convince ourselves first. Um we don't want to just go out to users with some half-baked idea and like run an AB test and then like look at the data. Um, I think there's other like products that that works for, but here at Notion, we're like we're pretty design focused. Uh, we are very critical of our own product. And so we really need to like be have conviction that the thing um is good before we start releasing it. And so when we were working on notion AI um like when I first joined we were doing all this sort of more advanced very technical stuff and we were finding it hard to get like product market fit internally. We found sparks of it. We found some people that were like super fans of what we were working on. Um and then for a lot of people they were just like man this is this is really complicated. It's really slow. Sometimes it works. uh when it breaks I'm like stuck and I'm like having to look at like generated code and like I I can't do that. Like I don't write code. And then people were just like, you know, kind of hitting like dead ends and we were like that's not a good sign. And so we did a couple revs on the way it worked and we found like an early version of this like aentic loop and when we shipped it internally all of a sudden all these people who were like maybe on the fence about like changing all the the AI features were like oh I I need this like I need this to work and like honestly because like we're so prototypy like it was very hack act together. It was slow. It was buggy. And like the moment for us was when we started getting all these bug reports. And it's like not good that we had like bugs and like things we needed to improve, but the volume of people who were like, "Oh, I need this fixed so that I can like um you know, do like do more revisions on my um product review or like people were just like coming to us and it's that feeling of of when the product is like being pulled out of you rather than you trying to like push what the product should be. And like people were just coming and saying like, "Oh, the uh agent is not good at using this block type or I wish it could like do more advanced querying on the database or the search results aren't like super accurate." Um like one one example of this near like the last mile of us shipping the agent is we had an engineer who was like, "I really wish I could like customize my own agent." And he had this idea where he was like, "What if we already have pages within notion? What if I just like made a dedicated page that is like the quote unquote personality of my agent?" And he just like built it, hacked it together, and like I I will admit I like used this or like I I saw us talking about it and I was like, "Ah, I don't know. Seems like kind of like a scrappy idea." And then I like used the early prototype and I was like, "Oh my god, this is so cool." I could influence the style and the tone. I could even put in like little snippets that's like when I ask you to do X, you do Y. And then all of a sudden, I'm like in my agent and without like any other keystrokes, I can be like do X and it just like does Y. And then it was like, oh my god, this is this is very cool. And it like unlocks this like possibility. But like yeah for for us we really we found that spark and then we went through the traditional um like product development where we brought in some like early adopters and asking for feedback and working really tightly with them and making sure that the the agent was solving problems for them. And the more and more we expanded our testing the more people were like just pulling the product out of us. Um and we knew like from that moment really early on that we like had something. Um, and and to be honest, I like I do not know how I would ever use notion like without this feature. And that's like me being like a user. And and that is to me like the most important thing is that I am like fully convinced that this is like a a worthwhile thing to build. >> Yeah. Ryan is is there uh it's sounds like it was kind of a steady with very early realization realization that there was some traction right as you mentioned um I think eval are very important >> a lot of companies talk about the importance of eval right for their specific domain hey what do the benchmarks say what you know what are the metrics say but you're saying hey dog fooding was essentially a big part of your evals actually the vibe I've you know this the sorts of things that you're you're doing personally this engineer that you refer to was uh that that that did this crazy thing um that then became super cool was was was it pretty much kind of the steady acceleration or was there any I guess I'm curious if it was any single particular breakthrough on on that um that tra trajectory that you know looking back um you you can point to as as as a real breakthrough. through through those bugs, through those issues. >> I I think it was really the um like the markdown stuff. Uh when we shipped that internally, it just the writing the the way the model could write got so much better. Um not only just like write but like reason. Uh it was just so much so much simpler um for the model to be able to work. And then I think maybe also our like uh our web tooling um being able to like fetch contents of a website, search the internet um and just kind of like seeing all of those pieces come together and may maybe like a really good example is when we had one of our first moments where we saw the agent effectively chain all of these tool calls together. So to be able to like read the current page that I'm on um go and search the internet uh for you know some subject that I'm that I'm maybe I'm researching something and then say like create a database fill out all the properties create views and then populate the database like essentially in one shot you know being able to ask it like read this page do some research on the internet and then set up like a task board for me to like work on and just seeing it like scaffold hold all of that and get it set up for you without you like having to do all this work bouncing between context tools um and whatever was Yeah, it was just kind of like mind-blowing at first. >> Ryan, I'm really curious. Okay, so you get this product market fit moment and my guess is that you've also already sort of seen that in your career at Instagram with certain features or things like that, right? So it becomes really clear like you talked about suddenly people are pulling the product out of you rather than you trying to push it onto them. Um where do you go from here with that? So clearly you've got something that's working really well. My guess is you're now being bombarded with like you know 500 things of people saying hey but I also want X and Y and Z and you know all these sorts of things. How do you sort of how do you sort of clarify that you know like the the whole sort of curation aspect of sort of saying yeah no no no okay we're just going to focus on this or we're just going to nail these key features that is incredibly challenging um because yeah we have uh a really diverse population of users from like I was saying from students to parents uh people running their home office or like a church on notion to Fortune 500 companies um that are running uh their projects and knowledge base and whatnot on notion. Um and so that is hard to figure out like what to do because you've got the the requests from those different um levels of customer are are wildly different. Um so we have to do a little bit of constant like rep prioritizing uh within there. Um and then internally we have ideas uh things that we want to try, things that we want to experiment and we certainly don't want to ignore innovation. You know, one thing that we're constantly doing, we have a a group of folks here who are on like the bleeding edge of AI research um and technology. constantly following what the frontier labs are doing and releasing and talking about so that we are prepared uh when new ideas and new paradigms come around. We don't want to be left behind. We want to take advantage of new things and at least try them and see how it fits within notion. We also have to listen to our customers um and figure out what they need. Uh but it is a challenge. I mean, one of the things that we're trying to be really careful about is like, you know what what's the saying that if all you have is a hammer, everything looks like a nail or whatever. And when people ask for new features, it's like, boy, we could just like add a tool to the model or to our agent and let it do that. Um, and that to me is a little bit of a slippery slope because the more tools that we add, the more decisions and the more options um, the model has to make. I mean, it's just the same way as like us. Like when I go to a restaurant, one of my biggest pet peeves is when I go to like a restaurant and they give me like the Cheesecake Factory menu where it's like, here's 20 pages of like food that you could order. And I'm like gh what do I what do I actually want? My ideal is like I go to a place and it's like here's four dishes and you get to pick. They're all excellent, but you have to pick between those four. And I'm like perfect. I know I will have a great time. So that's like the way we want to design our tools is like we want the uh the very like uh curated menu. Um so we have to be really careful of that. But we also, you know, don't want to limit the functionality of the agent. Um like something we're working on right now, we just released the ability for the agent to read comments that are within pages or or databases. um which we didn't launch with initially and it was probably our most requested feature and so that one made sense because so many people were asking for it that that pull of the product. Um but then it comes to other more like nuance stuff and perhaps it's a job better suited for MCP. Um, so if there's a more technical advanced feature that people need, maybe we can like folks on our support team can work with that customer to figure out how to solve their problem without necessarily adding a tool. Um, I will say like currently our biggest focus is like reliability and performance. Um, notion is a very complicated uh uh the like structure in blocks and databases. It's very complicated for the agent. So we have to give the agent lots of instructions and lots of documentation. We have to uh we we have like different models have like different layers or levels of like thinking that you can give it. And we're on like the higher level of reasoning and thinking whenever we're calling OpenAI or anthropic and that can feel slow sometimes when you're just like fix this typo and it's sitting there for like 10 seconds like thinking about how to do that. So, we're trying to figure out ways to make this feel a lot snappier, a lot lighter. Um, and then and then we're also working on custom agents, um, which is not fully shipped yet, but that is also built on our entire agentic loop. And so, making sure that that works, that's performant. Um, that that is a whole other suite of um complexities and things to to worry about. Um, but it's showing immense promise. Yeah, Ryan, the the reliance on on tools is a big one, and I'm thinking about our listeners here who are probably thinking through, okay, how best to do it. I could definitely relate to the confusion that we we keep hearing that agents have with a long list of tools. Um, you know, I I you know, some there's there's a a Mediterranean place in not far where where you know, I can walk in and okay, you got to choose the protein, you got to choose the carb, you got to choose this. Or you don't have to do that choosing. you could do this or you could do that and it's like um and and so I think agents are going to be smarter than probably me but but you still have that confusion. So, so, so I'm wondering are you talked about performance being a big one in terms of ranking >> I I think on on on the tool side what tools you use. You can't just add another tool. Can you talk a little bit about maybe what tools >> are emerging as as big ones or what what bucket tools are emerging or what classification or other practices are big? >> Yeah. Um, our our page tool is still probably like the most used um to both like read and write to pages. Uh, and because notion has I can't remember how many like different block types we have, but it's like it's so many. It's like over a hundred I think. Um, each of those tools has to be like hand maintained on like how we represent it to the model and then how the model can like write back to it. Um, so that's hard. We we got to go through the laundry list of all these things and make sure they work. Um, so we spend a lot of time doing that because it's like the most used tool. Um, and then we have our databases that uh we allow people to query them uh generate them. They can um add views to them. Um, and our views can be pretty complicated. If you've ever been in like uh chart views options in notion, there's all the different um types of charts that you can display and then the colors and the formatting um things that you show and don't show. We want to represent all of that to the agent um reasonably so that it can like work with that. Um so we go yeah we spend a lot of time just kind of doing the like here's all the things that you can do in notion. Let's make sure that the agent can do it reasonably well. And then sort of like finding the balance of like if we let it do too much, it's like more mistakes that it can make. It's more confused that it can get. So we have to be like pretty careful of that. So I I'm I'm really kind of curious. Right. you're you you've got all these you've got these in-house sort of tools and stuff like that that you're building yet you're you're using uh these you know models from anthropic from open AI and stuff like that at the same time they are kind of looking at all these products like notion and thinking like oh we could also have that tool we could also do that kind of thing so you've really got this kind of friendnemy thing right where you're you're kind of friends with them on one sense, but did you, you know, you got to feel at times like that you've got a target on your back that perhaps, you know, Anthropic wants to come after the enterprise area of notion. Uh, you know, OpenAI wants to come after the consumer side of that. How do you guys think about that? >> We have we have I I'll start by saying we have really great relationships with with the um the Frontier Labs. Um yeah, they do look to us as like product people. Um and then obviously we look to them as like the AI experts. Um you know I see both anthropic and open AI are are innovating on the product side alongside their models and um building things in the B2B space, the consumer space uh and whatnot. And I think that we don't necessarily want to go toe-to-toe with these huge labs. I mean they're extremely talented. They're wellunded. Um we believe our unique value is this collaborative space. Um this is in the like soul of notion and it's how notion works. Um and so that is I think what we are leaning into the most. You know we do not want like we're not going to build a notion version of like chat GPT. Um that doesn't really make a whole lot of sense. We want notion AI to be like our our our marketing um push is like that. These are teammates and we really want them to feel like teammates where um I can bring them into my workspace and either automate work or multitask things um or bring like expertise uh to a task um or to my work and less so the yeah like we're not going to make a notion generated video app or something um that wouldn't be too good. I guess more what I meant though was like do you feel the pressure to sort of develop your own secret source that is not model dependent that's sort of like stuff that they would have to think gee how are they doing that with our models we're not sure right kind of thing I you know like on one hand obviously they can you know sort of get a sense of what traffic is coming into their models I but it sounds like your whole middleware is really interesting in in that sort of sense and I'm curious just like do you you know is there an active conversation going on of like hey why don't we try and develop something that's you know really unique to us. Yeah, I that that is mostly how we approached this. Um like one thing, you know, it reminds me of of my time at Instagram. We were pretty weary to like vendor lock in. Um there there of course would be tools and products and APIs that would be Android specific and Apple specific and we would like to take advantage of those things but we would never want to build the core product around a single operating systems capability and the way that applies to notion is um I think the the different vendors have like their own kind of like here here's a good example like uh text replacement tools. um or they're now even coming out with like their own sort of like agentic tools and like we don't want to overfit to one like vendor's um API because uh that could change um the other vendor could come out with like a model that is like pretty exciting and we want to like experiment with that but if we've like overfitit for um you know the way one model behaves or a tool that it has we'll kind of end our like have cornered ourselves Um, and I think the other thing that we've learned over the last year is that like with all this like discovery that that the models work really well with Markdown, it's like we just kind of want to figure out and learn what these models are really good at and then figure out how to apply them to notion um and to the problems that our users have within notion and the way like the notion system works. Um, and so yeah, spending we spend almost all of our engineering effort on that middleware and you know our our AI like researchers and experts are the ones that are figuring out like oh this model is like now becoming really good at this new technology or this new technique and then we'll find a way to like apply that into notion and in a very like notion specific way. Do do you uh you know as you go through this do you sort of actively plot and plan that okay part of our agent will go for this model first then we'll go for another model. So we never let any vendor actually see the full sort of you know what's going on there. No, no, we're not. We're we're we're pretty open um both about like product and like what we're trying to do with the models because um the Frontier Labs are also trying to push the boundaries as well. Um and so we're frequently sharing like learnings about things that are working or not working. Um it really does feel like a rising tides lift all boats um sort of moment. >> So So Ryan, I I'm hearing you I I I want to follow up though on, you know, Sam Alman's been big about, hey, watch out. Don't don't develop in the road map of OpenAI because we're going to steamroll you, right? Don't build a rapper that can easily be wiped out by us. And when I saw them roll out OpenAI recently, you the apps in in ChatGpt, >> right? Now within my chat GPT feed, I can I can link to all these specialists, right? So and you noticed in their their launch, they have these specialist these domain experts. So So travel was a big one, right? Expedia, Booking.com, you could go straight to your your accounts from OpenAI and fiddle fiddle around there. >> Um >> for housing, you know, Zillow, uh Corsera, right? You you you could do banking. All those folks feel safe, right? The the those folks with the domain expertise, it's very different. Um book I I I think you you notion sounds like it's very dangerously in the road map recently and I'm not sure if it's obviously on purpose. I think this this stuff obviously came about relatively recently where Sam is is now talking more about being an assistant, right? He's talking about even a hardware device. And so maybe it wasn't by design, but it feels like it's becoming awfully close. Um, so are you sure you have something, you know, maybe I don't know if you can articulate what the differentiation is because it certainly feels like they have that connection tissue that they want to drive me anywhere. And you know, maybe second, I would just say, do you feel like OpenAI has provided a clear road map clear enough for folks like you? like what it and I'm just wondering what what what you're taking away from that. >> I definitely don't have any insight into OpenAI's roadmap. They launched new stuff that I'm like you were doing what uh all the time. Um which I think is cool. I I think it's very cool to watch. Um I I do think to me notions in a very sweet spot where like our expertise is the like multi-per real-time collaborative workspace. Um and I don't have a doubt in my mind that um other folks and and notion is not the only like multiplayer um B2B workspace app out there either. But I and I don't have any doubt in my mind that open or anthropic could build something could build something pretty great. Um but notion has over a decade of of uh experience in this space. Um and and not just on product and engineering but also like trust with companies and customers and users. Um and so we've developed quite a lot of expertise um in that. And you know we we don't necessarily want to like reframe notion as only AI like we to us we are using AI to like solve these collaborative issues for people. Um and so yeah I I don't think that I would see us ever going like toeto toe with open AAI. Um who knows this industry changes like every other day. I I'm kind of like chuckling because when you were talking about plans because we were recently having an internal conversation about like uh somebody asked me like what our AI team's roadmap is and I'm like I can tell you what we're doing until like Friday and that's like it uh and that's very much like by design because opportunities come up so fast new models drop um new prototypes show promise um new problems pop up with our infrastructure and so we're kind of like constantly ly pivoting and chasing um those new things. So yeah, it's like we're always kind of like on our heels and like ready to pivot and react. >> Ryan, it good point. Um is there one specific area you feel relatively confident that you just you you think you you have a dominant position in that's defensible in this overall area of context? I I think that our like search and connection is like world class. Um it is by far what I use Notion AI for. Um, I love being able to like write documents, edit documents, and manage databases, but on its own, I think it would be like a a nice feature, but when I can combine that with the context and retrieval that we've got um in addition to the like within notion, like the years and years of content and information from all of these different uh connections that we use like really sort of like um is the Yeah. the the the value to me like for example uh when I onboarded here it was like one of the best onboardings ever because instead of having to have an onboarding buddy that I'm like constantly peppering with questions I just am like asking notion AI how do I do this where do I find this or like why was this decision made and it can go back like five years in time and be like here is where like you know Ivan wanted to try feature X and then we shipped it or whatever um and that's like that's like so useful. Uh, and also like that information doesn't always have to be crystallized within notion. That conversation could have happened in Slack 2 years ago and notion would just whoop go and find it. It really just comes down to like to me like product and taste and execution. Um, and it's ultimately like why I joined Notion with my co-founders because we like love the product. Um, we love the like level of taste. It doesn't feel um like we're just cramming every feature that we could possibly think of. We're very very critical and have a very high bar for um what we actually ship and how polished it is. >> That definitely seems to be a theme across a lot of the the uh sort of people who are adopting AI is that this really is about curation about taste and and and you know I think notion is definitely seen as a taste maker. I'm curious sort of now as we're sort of starting to wind up, what advice do you have for other companies that are sort of getting into this, you know, that are in that position of where they Yeah, maybe they've got some kind of, you know, data, some kind of context. They're trying to provide better products for their their customers. They're, you know, they're a bit intimidated by Open AI, sort of saying that they're going to get steamrololled. What's your sort of take on it? and sort of, you know, if someone was sort of sitting next to you in the bar and they tell you, "Hey, uh, we're just starting out, like, you know, give us give us the secret sauce." Um, a couple things that come to mind is like the first is just you just got to channel the model. Like just do use the APIs the way they were meant to be used. Don't try to be fancy. Don't try to over complicate it. Use plain English. Um, you know, like like I mentioned, if I could if a a new hire if I could present my prompt or my instructions to a new hireer and they can generally understand it, that's like what you should be shooting for. Just like keep it very simple. Um, what's nice is that that sort of maps to just like traditional engineering best practices, too. I've seen abstractions and frameworks and code that are just like PhD level complexity and like my eyes like glaze over when I'm trying to like read, you know, some code or whatever. And that's like a good kind of like smell test of like maybe something's actually overly complex. Um, and the same goes for working with LLMs, like just keep it simple. Um, and then I think the other part is like you just got to try stuff. Um, I would I would also recommend like don't invest in evals really soon. Like just be very vibey. Like just try things and feel it. Um, to me evals are once you've got a sense of like product market fit and you want to like hone in on the accuracy, the quality, the latency or whatever. Um, I would not start with like eval to do exploratory product work. Um, like pre-product market fit. I would not bother with evals. I would just very much like yeah use vibes. >> Interesting. So what to get that product market fit? What do you sort of like how okay if we if you're you're sort of encouraging people not to use eval because that's it's kind of interesting because a lot of other people we're listening to are sort of saying evales eval. But you make a really nice point that the emails probably don't help that much when you're exploring what what are you know what are the key sort of things for exploring >> it's kind of just classic product development to me like how much are people using your thing you know retention retention retention retention if people are constantly using your AI feature you've nailed it um and I'm a big believer in like build things that solve your problems. Now, that's hard. It depends on the space, you know, if I'm building a um AI feature for lawyers. I'm not a lawyer. I don't know how any of that works. Uh so, that would be really challenging for me. And and that's more of like a career life lesson is like I feel like people should work in spaces that they're super passionate and knowledgeable about. Um and so like for me, working at Notion's great because I like productivity tools. um I like being productive and so I'm gonna build tools that like do that for me. Um but yeah, that's it. I don't think there's anything necessarily unique about um you know, the other thing I would mention is like really early on in product development is like don't worry about costs. Don't worry about how much you're spending uh or like on AI development, don't worry about how cost effective your AI feature is yet. Like those things can be optimized later. Um, and especially if you've built something that is incredibly valuable to people that you should like have a a pricing structure that reflects that value as well. Um, that doesn't put you underwater. Um, I early in in our previous startup, I think we were like really precious about how cost effective like our LLM features were. And it's like, well, 20 people use it, so who cares? You got to earn the right to like optimize the price and the margins, right? Over the summer, we we had our our our flagship conference and Andrew Ing came to speak and he was really big on this this notion of being fast, right? That we we needed over the summer, I think we still were in this kind of environment that speed was necessary. We, you know, we're early. Um and multiple other people chimed in in agreement to the point where he was saying, "Yeah, you know, eval um even guard rails, uh security, uh you got to prototype, get some things out there, then kind of build that redundancy." But I want to come back to something I think you've mentioned a couple times, which is this culture, right? And you talked about being an Instagram and Kev Kevin Zystrom was was I think became famous for you know just perfecting the you know the icon corners. You know there were many um uh you know sharing apps and photo sharing image sharing apps at the time but they broke through that taste that you're talking about and you talked about notion actually not shipping throwing tools as fa as fast as possible uh slowing down perhaps and actually caring about what you put out there. Are we still in the in the era of speed? I mean, kind of moving forward or are we in the era of slowing down? >> I think we're still in the era of speed. Um, and it's it is challenging to uh be like crafts people that have a really high bar for polish and then be in a space that like is moving at breakneck speed. Um, so you you you have for us we have to straddle the line of holding a high bar while not like slowing ourselves down. Um, and that that's pretty hard. And so sometimes we will have to be a little bit more tolerant of um, you know, bugs, glitches, like whatever. You we're we're never going to willingly like ship a bug. Uh but sometimes if the agent has we have this like a bit of air cover that like AI is non-deterministic and so like there is a I think a there's a higher level of like tolerance for it being like quirky and weird than there would be in like traditional software you know like the the Instagram point is a great example like we had such a high bar because we could control every single pixel of it. um with AI we we can't control as much. Um and even though Frontier Labs like don't necessarily know how these things work under the hood. Um and so that that gives us a bit of air cover to be a little experimental. Um but at the same time there are some principles that we just hold really dearly. Uh like one is permissions. Um we care very much about how uh we respect your permissions and permissions of content and people within your workspace. You know we never want to leak content. We want to be um aware of uh the dangers of fetching content from the internet. Um if the agent is ever changing content on your behalf, we want you to have a one-click way to undo that and restore what it did or or see what it did. So, you know, there's some places that we could be a little faster and looser. And then there's some areas where we're like, nope, like this is a red line that we're not going to cross. You know, we never want to make people's content um irreoverable. um or leaked. >> Where do you go from here? Well, like you've done you've done a bunch of stuff. It's been a really interesting conversation. I'm I'm really kind of curious to see and and not just just for you and for personally for Notion, but like where do you think as an industry we sort of go from here? >> Yeah, it's it's a pretty weird time. Um I don't know what things are going to look like in in a year, let alone like five years. Do you think like everyone's been talking about or you know I guess earlier in the year everyone was talking about 2025 being the year of agents. It's kind of you know I think Kapathy mentioned that it's the kind of probably the decade of agents which seems to make more sense to me. I you know is the future agents right? Do you sort of foresee that like uh a lot of this stuff is going to be agents rolling out? >> We're experimenting a lot with obviously with agents. Um, I think a custom agent bet is very exciting because this adds another layer of like autonomy um to our like notion agents and so we're we're really excited about that. Um, I I agree with Carpathy. I think it's it's a decade of agents. Um, I think his point about like every nine of reliability taking enormous like the same amount of effort I think is completely true. Um, I've seen it firsthand with uh what we're doing on notion AI where we've got things like pretty stable, but that last like few percent uh you know in some tool error rate or whatever, it's really hard to nail because it's not there is no like silver bullet. It is a bunch of small things that you have to fix. Uh and then a new model will come out and have its own quirks and like things that you have to patch. Um so that is like really challenging but but fun. It's like a fun challenge. What I'm most excited about is like extending model capabilities and modality. I am not wholly convinced that the future is chat boxes. Um I think there's a lot more interesting stuff going on. I'm I'm really excited about all these companies building like AI browsers, not just, you know, a popup in the side where I can like chat with the web page, but automation and um like more context aware about like what I'm doing. You know, AI is essentially like with you and available at all time and has more and more and more context. So I think that that's for us at at notion what we're um investing a lot in right now is like the more context the more information the better the AI is going to perform. So like how can we give it more context. >> Ryan this has been a fantastic conversation. Thank you. Thank you very much for sharing. You you did intrigue me though you know by ending on customized agents. Can you can you just give us you know maybe a preview or an outline of the types of things that are coming down moving forward? You know, is this maybe more relevant for the enterprise or or are you talking about more for the assistant in terms of the the assistant for the individual? >> I I do think it solves problems for both. Um I would say that enterprises and and well just companies will probably see the immediate value from custom agents. Like for instance, we're using it to power um our IT departments, our help desk departments. It's helping our our sales groups, our customer support groups. For an example, we have like an IT channel in Slack. And you can ask a question about, you know, oh, my computer's acting up or I need a new um cable for my monitor. And our bot will reply either and pull information like from our help docs from previous uh requests. and then if it can't answer your question, it'll file a ticket for our IT team to then go look into. They'll look into it and then then handle your thing where previously that was like either a person um in Slack constantly monitoring that stuff or another like uh app or service that we had to manage that was like kind of doing that and not as deeply integrated as as Notion is. But I I've also seen a bunch of great like personal productivity uses for it. Um, something that I started doing is I have a custom agent that is like my work journal. Um, and so at the end of every single day, it like looks across my Slack channels, my pull requests, um, my documents. Um, you know, we have we have meeting notes within notion, so it can see all the meetings that I was in. It sucks up all of that context and it writes like a little 10point blurb about like here's the things Ryan did today. And then it stuffs that into a database that becomes like my my journal. Um I like kind of journaling. I like kind of keeping tabs on what I do. I can be so busy that I like forget all the minutiae of like the things we did and accomplished. Um and so now instead of me having to take time and like go and write that every single day, I just have a custom agent that plops a new page uh into this database and I can review it uh if I want or not. Um or I can do even like more meta, you know, summarization over the uh the month of November. What all did I do? And all that information is there. >> Fascinating. All right. The whole conversation has been very fascinating. Or Ryan, thank you so much for for joining us on the pod. Um we certainly learned a lot. Uh it's very interesting to hear what a startup like Notion is doing. uh and and thank you for being so open about, you know, a number of the different topics of how you've actually sort of built this experience. Thank you very much. >> Thank you so much for having me. This was a blast. Thank you, Ryan. >> And special thanks to our presenting sponsor, Outshift by Cisco. You can learn more about their work on the internet of agents via their Linux Foundation project, agy.org. This open-source project enables agents to work at scale across any vendor or framework with trusted and secure discovery, identity access, and observability. For more stories about the AI revolution, like and subscribe to the podcast and check out venturebeat.com to sign up for our newsletters.



---

*Processed from inbox on 2025-11-19*
*Original file: 2025-11-19_ai_venturebeat-launches-beyond-the-pilot--a-new-po.md*
