---
title: MiniMax-M2: New Leading Open-Source LLM for Agentic Tool Calling and Enterprise Workflows
source: 2025-10-29_ai_minimax-m2-is-the-new-king-of-open-source-llms-es.md
date_added: 2025-10-30
last_updated: 2025-10-30
tags: [open-source-llm, agentic-ai, enterprise-ai, mixture-of-experts, tool-calling, ai-automation, developer-tools]
source_type: article
---

## Summary

- MiniMax-M2 ranks as the highest-performing open-source LLM globally, particularly excelling in agentic tool-calling tasks like autonomous web search and application integration
- Released under MIT License, making it freely available for commercial enterprise use with support for OpenAI and Anthropic API standards
- Uses efficient Mixture-of-Experts architecture (230B total parameters, 10B active) enabling deployment on just 4 NVIDIA H100 GPUs, significantly reducing infrastructure costs
- Achieves near-proprietary model performance (comparable to GPT-5 and Claude Sonnet 4.5) on benchmarks measuring coding, reasoning, and multi-step task execution
- Particularly strong in developer workflows including automated testing, multi-file code edits, and agentic planning with external tool integration

## Key Insights

- Open-source AI models are reaching parity with proprietary systems for enterprise use cases, eliminating vendor lock-in while reducing costs
- Agentic capabilities (autonomous planning, tool use, error recovery) are becoming critical differentiators for enterprise AI deployment
- Efficient MoE architecture enables frontier-level performance on accessible hardware, democratizing advanced AI for mid-size organizations
- Chinese AI companies continue advancing open-source AI development, creating viable alternatives to Western proprietary models
- Models optimized for developer workflows and CI/CD integration represent significant opportunities for operational efficiency gains

## Full Content

---
source: VentureBeat - AI
url: https://venturebeat.com/ai/minimax-m2-is-the-new-king-of-open-source-llms-especially-for-agentic-tool
published: Mon, 27 Oct 2025 19:01:00 GMT
relevance_score: 7
primary_topic: Open-source LLM for agentic automation and business workflows
fetched: 2025-10-29T21:45:56.756693
category: AI News
---

# MiniMax-M2 is the new king of open source LLMs (especially for agentic tool calling)

**Source**: VentureBeat - AI
**URL**: https://venturebeat.com/ai/minimax-m2-is-the-new-king-of-open-source-llms-especially-for-agentic-tool
**Published**: Mon, 27 Oct 2025 19:01:00 GMT
**Relevance Score**: 7/10

## Summary

<p>Watch out, DeepSeek and Qwen! There&#x27;s a new king of open source large language models (LLMs), especially when it comes to something enterprises are increasingly valuing: agentic tool use — that is, the ability to go off and use other software capabilities like web search or bespoke applications — without much human guidance. </p><p>That model is none other than <a href="https://x.com/MiniMax__AI/status/1982674798649160175"><b>MiniMax-M2</b></a>, the latest LLM from the Chinese startup of the same name. And in a big win for enterprises globally, the model is available under a permissive, enterprise-friendly MIT License, meaning it is made available freely for developers to take, deploy, retrain, and use how they see fit — even for commercial purposes. It can be found on <a href="https://huggingface.co/MiniMaxAI/MiniMax-M2">Hugging Face</a>, <a href="https://github.com/MiniMax-AI/MiniMax-M2">GitHub</a> and <a href="https://www.modelscope.cn/models/MiniMax/MiniMax-M2">ModelScope</a>, as well as through<a href="https://platform.minimax.io/docs/guides/text-generation"> MiniMax&#x27;s API here.</a> It supports OpenAI and Anthropic API standards, as well, making it easy for customers of said proprietary AI startups to shift out their models to MiniMax&#x27;s API, if they want.</p><p>According to <a href="https://x.com/ArtificialAnlys/status/1982714153375854998">independent evaluations by Artificial Analysis</a>, a third-party generative AI model benchmarking and research organization, M2 now ranks first among all open-weight systems worldwide on the Intelligence Index—a composite measure of reasoning, coding, and task-execution performance. </p><p>In agentic benchmarks that measure how well a model can plan, execute, and use external tools—skills that power coding assistants and autonomous agents—MiniMax’s own reported results, following the Artificial Analysis methodology, show τ²-Bench 77.2, BrowseComp 44.0, and FinSearchComp-global 65.5. </p><p>These scores place it at or near the level of top proprietary systems like GPT-5 (thinking) and Claude Sonnet 4.5, making <b>MiniMax-M2 the highest-performing open model yet released for real-world agentic and tool-calling tasks.</b></p><h3><b>What It Means For Enterprises and the AI Race</b></h3><p>Built around an efficient Mixture-of-Experts (MoE) architecture, MiniMax-M2 delivers high-end capability for agentic and developer workflows while remaining practical for enterprise deployment.</p><p>For technical decision-makers, the release marks an important turning point for open models in business settings. MiniMax-M2 combines frontier-level reasoning with a manageable activation footprint—just 10 billion active parameters out of 230 billion total. </p><p>This design enables enterprises to operate advanced reasoning and automation workloads on fewer GPUs, achieving near-state-of-the-art results without the infrastructure demands or licensing costs associated with proprietary frontier systems.</p><p>Artificial Analysis’ data show that MiniMax-M2’s strengths go beyond raw intelligence scores. The model leads or closely trails top proprietary systems such as GPT-5 (thinking) and Claude Sonnet 4.5 across benchmarks for end-to-end coding, reasoning, and agentic tool use. </p><p>Its performance in τ²-Bench, SWE-Bench, and BrowseComp indicates particular advantages for organizations that depend on AI systems capable of planning, executing, and verifying complex workflows—key functions for agentic and developer tools inside enterprise environments.</p><p>As LLM engineer Pierre-Carl Langlais aka <a href="https://x.com/Dorialexander/status/1982761110228127954">Alexander Doria posted on X</a>: &quot;MiniMax [is] making a case for mastering the technology end-to-end to get actual agentic automation.&quot;</p><h3><b>Compact Design, Scalable Performance</b></h3><p>MiniMax-M2’s technical architecture is a sparse Mixture-of-Experts model with 230 billion total parameters and 10 billion active per inference. </p><p>This configuration significantly reduces latency and compute requirements while maintaining broad general intelligence. </p><p>The design allows for responsive agent loops—compile–run–test or browse–retrieve–cite cycles—that execute faster and more predictably than denser models.</p><p>For enterprise technology teams, this means easier scaling, lower cloud costs, and reduced deployment friction.<b> </b>According to Artificial Analysis, <b>the model can be served efficiently on as few as four NVIDIA H100 GPUs at FP8 precision</b>, a setup well within reach for mid-size organizations or departmental AI clusters.</p><h3><b>Benchmark Leadership Across Agentic and Coding Workflows</b></h3><p>MiniMax’s benchmark suite highlights strong real-world performance across developer and agent environments. The figure below, released with the model, compares MiniMax-M2 (in red) with several leading proprietary and open models, including GPT-5 (thinking), Claude Sonnet 4.5, Gemini 2.5 Pro, and DeepSeek-V3.2.</p><p>MiniMax-M2 achieves top or near-top performance in many categories:</p><ul><li><p>SWE-bench Verified: 69.4 — close to GPT-5’s 74.9</p></li><li><p>ArtifactsBench: 66.8 — above Claude Sonnet 4.5 and DeepSeek-V3.2</p></li><li><p>τ²-Bench: 77.2 — approaching GPT-5’s 80.1</p></li><li><p>GAIA (text only): 75.7 — surpassing DeepSeek-V3.2</p></li><li><p>BrowseComp: 44.0 — notably stronger than other open models</p></li><li><p>FinSearchComp-global: 65.5 — best among tested open-weight systems</p></li></ul><p>These results show MiniMax-M2’s capability in executing complex, tool-augmented tasks across multiple languages and environments—skills increasingly relevant for automated support, R&amp;D, and data analysis inside enterprises.</p><h3><b>Strong Showing in Artificial Analysis’ Intelligence Index</b></h3><p>The model’s overall intelligence profile is confirmed in the latest <b>Artificial Analysis Intelligence Index v3.0</b>, which aggregates performance across ten reasoning benchmarks including MMLU-Pro, GPQA Diamond, AIME 2025, IFBench, and τ²-Bench Telecom.</p><p><b>MiniMax-M2 scored 61 points</b>, ranking as the highest open-weight model globally and following closely behind GPT-5 (high) and Grok 4. </p><p>Artificial Analysis highlighted the model’s balance between technical accuracy, reasoning depth, and applied intelligence across domains. For enterprise users, this consistency indicates a reliable model foundation suitable for integration into software engineering, customer support, or knowledge automation systems.</p><h3><b>Designed for Developers and Agentic Systems</b></h3><p>MiniMax engineered M2 for end-to-end developer workflows, enabling multi-file code edits, automated testing, and regression repair directly within integrated development environments or CI/CD pipelines. </p><p>The model also excels in agentic planning—handling tasks that combine web search, command execution, and API calls while maintaining reasoning traceability.</p><p>These capabilities make MiniMax-M2 especially valuable for enterprises exploring autonomous developer agents, data analysis assistants, or AI-augmented operational tools. </p><p>Benchmarks such as Terminal-Bench and BrowseComp demonstrate the model’s ability to adapt to incomplete data and recover gracefully from intermediate errors, improving reliability in production settings.</p><h3><b>Interleaved Thinking and Structured Tool Use</b></h3><p>A distinctive aspect of MiniMax-M2 is its interleaved thinking format, which maintains visible reasoning traces between &lt;think&gt;...&lt;/think&gt; tags.</p><p>This enables the model to plan and verify steps across multiple exchanges, a critical feature for agentic reasoning. MiniMax advises retaining these segments when passing conversation history to preserve the model’s logic and continuity.</p><p>The company also provides a <a href="https://huggingface.co/MiniMaxAI/MiniMax-M2/blob/main/docs/tool_calling_guide.md">Tool Calling Guide</a> on Hugging Face, detailing how developers can connect external tools and APIs via structured XML-style calls. </p><p>This functionality allows MiniMax-M2 to serve as the reasoning core for larger agent frameworks, executing dynamic tasks such as search, retrieval, and computation through external functions.</p><h3><b>Open Source Access and Enterprise Deployment Options</b></h3><p>Enterprises can access the model through the <a href="https://platform.minimax.io/docs/guides/platform-intro">MiniMax Open Platform API </a>and <a href="https://agent.minimax.io/">MiniMax Agent interface</a> (a web chat similar to ChatGPT), both currently free for a limited time.</p><p>MiniMax recommends SGLang and vLLM for efficient serving, each offering day-one support for the model’s unique interleaved reasoning and tool-calling structure. </p><p>Deployment guides and parameter configurations are available through MiniMax’s documentation.</p><h3><b>Cost Efficiency and Token Economics</b></h3><p>As Artificial Analysis noted, <a href="https://platform.minimax.io/docs/guides/pricing?key=68c79eb793ce7d2b318c5975">MiniMax’s API pricing</a> is set at <b>$0.30 per million input tokens</b> and <b>$1.20 per million output tokens</b>, among the most competitive in the open-model ecosystem. </p><table><tbody><tr><td><p><b>Provider</b></p></td><td><p><b>Model (doc link)</b></p></td><td><p><b>Input $/1M</b></p></td><td><p><b>Output $/1M</b></p></td><td><p><b>Notes</b></p></td></tr><tr><td><p>MiniMax</p></td><td><p><a href="https://www.minimax.io/platform/document/pricing?key=68c79eb793ce7d2b318c5975">MiniMax-M2</a></p></td><td><p><b>$0.30</b></p></td><td><p><b>$1.20</b></p></td><td><p>Listed under “Chat Completion v2” for M2. </p></td></tr><tr><td><p>OpenAI</p></td><td><p><a href="https://openai.com/api/pricing/">GPT-5</a></p></td><td><p><b>$1.25</b></p></td><td><p><b>$10.00</b></p></td><td><p>Flagship model pricing on OpenAI’s API pricing page. </p></td></tr><tr><td><p>OpenAI</p></td><td><p><a href="https://openai.com/api/pricing/">GPT-5 mini</a></p></td><td><p><b>$0.25</b></p></td><td><p><b>$2.00</b></p></td><td><p>Cheaper tier for well-defined tasks. </p></td></tr><tr><td><p>Anthropic</p></td><td><p><a href="https://docs.claude.com/en/docs/about-claude/pricing">Claude Sonnet 4.5</a></p></td><td><p><b>$3.00</b></p></td><td><p><b>$15.00</b></p></td><td><p>Anthropic’s current per-MTok list; long-context (&gt;200K input) uses a premium tier. </p></td></tr><tr><td><p>Google</p></td><td><p><a href="https://ai.google.dev/gemini-api/docs/pricing">Gemini 2.5 Flash (Preview)</a></p></td><td><p><b>$0.30</b></p></td><td><p><b>$2.50</b></p></td><td><p>Prices include “thinking tokens”; page also lists cheaper Flash-Lite and 2.0 tiers. </p></td></tr><tr><td><p>xAI</p></td><td><p><a href="https://x.ai/api">Grok-4 Fast (reasoning)</a></p></td><td><p><b>$0.20</b></p></td><td><p><b>$0.50</b></p></td><td><p>“Fast” tier; xAI also lists Grok-4 at $3 / $15. </p></td></tr><tr><td><p>DeepSeek</p></td><td><p><a href="https://api-docs.deepseek.com/quick_start/pricing">DeepSeek-V3.2 (chat)</a></p></td><td><p><b>$0.28</b></p></td><td><p><b>$0.42</b></p></td><td><p>Cache-hit input is $0.028; table shows per-model details. </p></td></tr><tr><td><p>Qwen (Alibaba)</p></td><td><p><a href="https://www.alibabacloud.com/help/en/model-studio/models">qwen-flash (Model Studio)</a></p></td><td><p><b>from $0.022</b></p></td><td><p><b>from $0.216</b></p></td><td><p>Tiered by input size (≤128K, ≤256K, ≤1M tokens); listed “Input price / Output price per 1M”. </p></td></tr><tr><td><p>Cohere</p></td><td><p><a href="https://cohere.com/pricing">Command R+ (Aug 2024)</a></p></td><td><p><b>$2.50</b></p></td><td><p><b>$10.00</b></p></td><td><p>First-party pricing page also lists Command R ($0.50 / $1.50) and others. </p></td></tr></tbody></table><p><b>Notes &amp; caveats (for readers):</b></p><ul><li><p>Prices are USD per <b>million</b> tokens and can change; check linked pages for updates and region/endpoint nuances (e.g., Anthropic long-context &gt;200K input, Google Live API variants, cache discounts). </p></li><li><p>Vendors may bill extra for server-side tools (web search, code execution) or offer batch/context-cache discounts. </p></li></ul><p>While the model produces longer, more explicit reasoning traces, its sparse activation and optimized compute design help maintain a favorable cost-performance balance—an advantage for teams deploying interactive agents or high-volume automation systems.</p><h3><b>Background on MiniMax — an Emerging Chinese Powerhouse</b></h3><p>MiniMax has quickly become one of the most closely watched names in China’s fast-rising AI sector. </p><p>Backed by Alibaba and Tencent, the company moved from relative obscurity to international recognition within a year—first through breakthroughs in AI video generation, then through a series of open-weight large language models (LLMs) aimed squarely at developers and enterprises.</p><p>The company first captured <a href="https://venturebeat.com/ai/minimaxs-ai-video-tool-can-create-star-wars-battles-in-seconds-heres-why-that-matters">global attention in late 2024 with its AI video generation tool</a>, “video-01,” which demonstrated the ability to create dynamic, cinematic scenes in seconds. VentureBeat described how the model’s launch sparked widespread interest after online creators began sharing lifelike, AI-generated footage—most memorably, a viral clip of a <i>Star Wars</i> lightsaber duel that drew millions of views in under two days. </p><p>CEO Yan Junjie emphasized that the system outperformed leading Western tools in generating human movement and expression, an area where video AIs often struggle. The product, later commercialized through MiniMax’s <i>Hailuo</i> platform, showcased the startup’s technical confidence and creative reach, helping to establish China as a serious contender in generative video technology.</p><p>By early 2025, MiniMax had turned its attention to long-context language modeling, unveiling the <a href="https://venturebeat.com/ai/minimax-unveils-its-own-open-source-llm-with-industry-leading-4m-token-context">MiniMax-01 series, including MiniMax-Text-01 and MiniMax-VL-01</a>. These open-weight models introduced an unprecedented 4-million-token context window, doubling the reach of Google’s Gemini 1.5 Pro and dwarfing OpenAI’s GPT-4o by more than twentyfold. </p><p>The company continued its rapid cadence with the <a href="https://venturebeat.com/ai/minimax-m1-is-a-new-open-source-model-with-1-million-token-context-and-new-hyper-efficient-reinforcement-learning">MiniMax-M1 release in June 2025</a>, a model focused on long-context reasoning and reinforcement learning efficiency. M1 extended context capacity to 1 million tokens and introduced a hybrid Mixture-of-Experts design trained using a custom reinforcement-learning algorithm known as CISPO. Remarkably, VentureBeat reported that MiniMax trained M1 at a total cost of about $534,700, roughly one-tenth of DeepSeek’s R1 and far below the multimillion-dollar budgets typical for frontier-scale models. </p><p>For enterprises and technical teams, MiniMax’s trajectory signals the arrival of a new generation of cost-efficient, open-weight models designed for real-world deployment. Its open licensing—ranging from Apache 2.0 to MIT—gives businesses freedom to customize, self-host, and fine-tune without vendor lock-in or compliance restrictions. </p><p>Features such as structured function calling, long-context retention, and high-efficiency attention architectures directly address the needs of engineering groups managing multi-step reasoning systems and data-intensive pipelines.</p><p>As MiniMax continues to expand its lineup, the company has emerged as a key global innovator in open-weight AI, combining ambitious research with pragmatic engineering. </p><h3><b>Open-Weight Leadership and Industry Context</b></h3><p>The release of MiniMax-M2 reinforces the growing leadership of Chinese AI research groups in open-weight model development. </p><p>Following earlier contributions from DeepSeek, Alibaba’s Qwen series, and Moonshot AI, MiniMax’s entry continues the trend toward open, efficient systems designed for real-world use. </p><p>Artificial Analysis observed that MiniMax-M2 exemplifies a broader shift in focus toward agentic capability and reinforcement-learning refinement, prioritizing controllable reasoning and real utility over raw model size.</p><p>For enterprises, this means access to a state-of-the-art open model that can be audited, fine-tuned, and deployed internally with full transparency. </p><p>By pairing strong benchmark performance with open licensing and efficient scaling, MiniMaxAI positions MiniMax-M2 as a practical foundation for intelligent systems that think, act, and assist with traceable logic—making it one of the most enterprise-ready open AI models available today.</p>

## Scoring Analysis

**Primary Topic**: Open-source LLM for agentic automation and business workflows
**Reason**: While not specifically marketing-focused, MiniMax-M2's agentic tool-calling capabilities, cost-efficiency ($0.30-$1.20 per million tokens), and enterprise automation features are highly relevant for marketing teams exploring AI-powered campaign automation, content workflows, and API integrations. The practical deployment guidance and competitive pricing make it actionable for marketing automation strategies.

---

*Article fetched by AI news monitor*
*Full content will be processed by knowledge base system*

**Original URL**: https://venturebeat.com/ai/minimax-m2-is-the-new-king-of-open-source-llms-especially-for-agentic-tool


---

*Processed from inbox on 2025-10-30*
*Original file: 2025-10-29_ai_minimax-m2-is-the-new-king-of-open-source-llms-es.md*
